
# coding: utf-8

# ### 七种理解数据的方法
# 
# - 简单查看数据
# - 审查数据的维度
# - 审查数据的类型和属性
# - 总结查看数据分类的分布情况
# - 统计分析数据
# - 理解数据属性的相关性
# - 审查数据的分布情况
# 
# 

# In[4]:


# 简单查看数据
from pandas import read_csv
filename = 'data/pima_data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
data = read_csv(filename, names=names) # 手动指定头部


# In[5]:


peek = data.head(10)
print(peek)


# ### 了解数据的维度
# 
# 知道数据有多少行，多少列很重要，通过pandas的shape属性可以知道。
# 
# 

# In[6]:


print(data.shape)


# ### 数据的属性和类型
# 
# 了解数据是什么类型，方便下一步的计算。

# In[8]:


print(data.dtypes)


# 可以看出来，数据都是数值类型，两个是浮点数，其他都是整数类型。

# ### describe， 描述性统计信息

# In[10]:


from pandas import set_option
set_option('precision',4)
print(data.describe())


# ### 数据分组分布 -- 适用于分类算法
# 
# 知道每个类有多少数据，看数据的分布是否均衡，如果不均衡，我们就对数据进行预处理，再进入下一步。

# In[11]:


print(data.groupby('class').size())


# 可以看出数据有两个类别，一类有500个，另一类有268个数据，不是特别均衡，但是在同一个数量级。

# ### 数据属性的相关性探索
# 
# 在机器学习中，当数据的关联性比较高时，有些算法的性能会降低，比如线性回归和逻辑斯蒂回归算法等。
# 
# 当数据特征相关性比较高时，可以考虑对特征进行**降维**，使用`corr()`可以查看数据特征值之间的关联关系。

# In[12]:


set_option('display.width', 100)
# 设置数据精度
set_option('precision', 2)
print(data.corr(method='pearson'))


# ### 数据的分布分析
# 
# 机器学习算法一般假设数据遵循高斯分布，所以通过分析数据的高斯分布情况，可以确认数据的偏离情况。用`skew()`方法计算所有数据属性的高斯分布偏离情况。数据接近0时表示数据的偏差很小。

# In[13]:


print(data.skew())


# ### 总结
# 
# 对数据的分析是机器学习的重要步骤，只有对数据有足够的理解，才能选择出有效的算法来建立模型。上面列出的7个方法，也是7个角度，7个步骤。
# 
# 审查数据时，还有以下几个技巧：
# 
# - 审查数字，观察思考数据的特点，找到数据的内在关联以及对解决问题的帮助
# - 问为什么，观察数据时，多问几个为什么
# - 写下想法，边观察边记录自己的想法，这些想法在后面的步骤有大用
